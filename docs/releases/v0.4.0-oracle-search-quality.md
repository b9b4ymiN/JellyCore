# v0.4.0 — Oracle Search Quality

> **Type:** Minor (algorithm improvements + bug fix, no breaking changes)  
> **Scope:** Oracle V2 search ranking, `oracle_learn` ChromaDB fix, agent prompt tuning  
> **Risk:** Low — internal scoring changes, no API changes, fully backward compatible  
> **Est. Effort:** ~2 hours

---

## Background

Oracle V2 `0.3.0-nightly` มี 3 จุดที่กระทบ search quality:

1. **Bug** — `oracle_learn` เขียนลง SQLite + FTS5 แต่**ข้าม ChromaDB** ทำให้ learning ใหม่หายจาก vector search จนกว่า full re-index
2. **Scoring** — Hybrid merge ใช้ `max(score_fts, score_vector) + 0.1` ซึ่ง naive เกินไป doc ที่ปรากฏใน FTS อย่างเดียวก็อาจได้ score สูงกว่า doc ที่ match ทั้งสองระบบ
3. **Recency** — Doc เพิ่งเรียนรู้เมื่อวาน กับ doc อายุ 2 ปี score เท่ากันถ้า relevance เท่ากัน

---

## Changes

### Step 1 — Fix `oracle_learn` ChromaDB indexing

**File:** `oracle-v2/src/server/handlers.ts` → `handleLearn()`  
**Problem:** หลัง insert SQLite + FTS5 แล้ว ไม่ได้เรียก ChromaDB `addDocuments()`  
**Fix:** เพิ่ม ChromaDB upsert หลัง FTS5 insert

```
handleLearn()
  ├── write markdown file     ✅ (existing)
  ├── INSERT oracle_documents  ✅ (existing)
  ├── INSERT oracle_fts        ✅ (existing)
  ├── chromaClient.addDocuments([...])  ← NEW
  ├── logLearning()            ✅ (existing)
  └── searchCache.invalidate() ✅ (existing)
```

**Details:**
- ใช้ `getChromaClient()` singleton ที่มีอยู่แล้ว (บรรทัด 21-33)
- `addDocuments()` รองรับ sub-batch 10 docs อยู่แล้ว (แก้ OOM ไปก่อนหน้า)
- Metadata: `{ type: 'learning', source_file, concepts }`
- ถ้า ChromaDB connection fail → catch แล้ว log warning, ไม่ให้ learn endpoint fail ทั้ง request (FTS5 ยังใช้ได้)

**Verify:** เรียก `POST /api/learn` → ค้นหาด้วย `mode: 'vector'` → ต้องเจอ doc ใหม่

---

### Step 2 — Reciprocal Rank Fusion (RRF) scoring

**File:** `oracle-v2/src/server/handlers.ts` → `combineSearchResults()`  
**Problem:** `max(score_fts, score_vector) + 0.1` ไม่ robust — bonus แบน 0.1 ไม่คำนึงถึงตำแหน่ง rank

**Replace with Reciprocal Rank Fusion (RRF):**

```
rrf_score(d) = 1/(k + rank_fts(d)) + 1/(k + rank_vector(d))
```

- `k = 60` (ค่ามาตรฐาน จาก Cormack et al. 2009)
- Doc ที่อยู่ใน FTS อย่างเดียว: `1/(k + rank_fts)` (ได้แค่ขาเดียว)
- Doc ที่อยู่ใน vector อย่างเดียว: `1/(k + rank_vector)`
- Doc ที่อยู่ทั้งสอง: ผลรวมทั้งสองขา → ได้ score สูงขึ้นตามธรรมชาติ

**ทำไม RRF ดีกว่า:**
- Parameter-free (แค่ k=60)
- ไม่ต้อง normalize score ข้ามระบบ (ใช้ rank position ตรงๆ)
- เป็นมาตรฐานใน IR research
- Doc ที่ match ทั้ง FTS + vector ได้ boost โดยธรรมชาติ ไม่ต้อง hardcode bonus

**Signature change:** `combineSearchResults(fts, vector)` — input/output เหมือนเดิม, เปลี่ยนแค่ internal scoring  
**Side effect:** `normalizeRank()` ยังคงใช้สำหรับ FTS-only mode (`mode: 'fts'`) ไม่ต้องลบ

---

### Step 3 — Recency boost

**File:** `oracle-v2/src/server/handlers.ts` → `combineSearchResults()`  
**ทำใน function เดียวกับ Step 2**

```
recencyBoost(d) = 0.05 × max(0, 1 - daysSince(d.createdAt) / 365)
```

- Doc อายุ 0 วัน: +0.05
- Doc อายุ 6 เดือน: +0.025
- Doc อายุ 1 ปีขึ้นไป: +0.0
- Boost น้อยพอที่ไม่ override relevance (RRF score range: ~0.016–0.033 ต่อขา)

**Prerequisite:** `createdAt` ต้องถูก pass มาใน `SearchResult` — ตรวจสอบว่า FTS query และ vector query return `createdAt` หรือยัง ถ้ายังต้องเพิ่ม JOIN กับ `oracle_documents.createdAt`

---

### Step 4 — Agent proactive learning instructions

**File:** `groups/global/CLAUDE.md` → section "Memory"  
**ไม่กระทบ code** — แก้แค่ prompt instructions

**เพิ่ม:**
```markdown
## Proactive Learning

Use `mcp__oracle__oracle_learn` to save reusable knowledge:
- เมื่อ user สอนข้อมูลใหม่ที่มีคุณค่า → learn ทันที
- เมื่อแก้ bug สำเร็จ → learn pattern/solution ที่ค้นพบ
- เมื่อ user แสดง preference ชัดเจน → learn preference

ไม่ต้อง learn ทุกอย่าง — เฉพาะ reusable knowledge ที่จะเป็นประโยชน์ในอนาคต
ไม่ต้องขออนุญาต — ถ้าเห็นว่าควร learn ก็ทำเลย
```

**ทำไมไม่สร้าง background extraction system:**
- Agent เห็น full context อยู่แล้ว → ตัดสินใจ learn ได้ดีกว่า background process
- ไม่เพิ่ม LLM cost
- ไม่เสี่ยง learn garbage (agent มี judgment)
- Pre-compact hook archive transcript อยู่แล้ว → ข้อมูลไม่หาย

---

## File Changelist

| File | Change | LOC est. |
|------|--------|----------|
| `oracle-v2/src/server/handlers.ts` | Fix `handleLearn()` + rewrite `combineSearchResults()` | ~40 |
| `oracle-v2/src/server/handlers.ts` | Add recency boost to RRF scoring | ~10 |
| `groups/global/CLAUDE.md` | Add "Proactive Learning" section | ~10 |
| `oracle-v2/package.json` | Bump version `0.3.0-nightly` → `0.4.0` | 1 |

**Total:** ~60 lines changed  
**Services to rebuild:** Oracle V2 only (`docker compose up -d --build oracle`)  
**Agent container rebuild:** ไม่ต้อง (CLAUDE.md mount แบบ bind-mount อ่านตรงจาก host)

---

## Verification

```bash
# 1. After Step 1 — oracle_learn indexes to ChromaDB
curl -X POST http://localhost:47778/api/learn \
  -H 'Content-Type: application/json' \
  -d '{"pattern": "test pattern for vector indexing", "source": "test"}'

curl http://localhost:47778/api/search?q=test+pattern+vector&mode=vector
# → ต้องเจอ doc ใหม่

# 2. After Step 2-3 — RRF + recency
curl http://localhost:47778/api/search?q=pattern&mode=hybrid
# → doc ใหม่ที่ match ทั้ง FTS+vector ต้องอยู่ top
# → doc ใหม่กว่าควรอยู่สูงกว่า doc เก่าที่ score ใกล้กัน

# 3. After Step 4 — agent proactive learning
# ส่งข้อความผ่าน Telegram สอนข้อมูลใหม่ → ตรวจว่า agent เรียก oracle_learn เอง
```

---

## Decisions

| Decision | Rationale |
|----------|-----------|
| RRF over learned weights | Parameter-free, ไม่ต้อง training data, มาตรฐาน IR |
| Recency boost 0.05 cap | น้อยพอไม่ override relevance แต่แยก tie-breaking ได้ |
| ไม่ทำ conversation-aware re-ranking | Agent = context layer อยู่แล้ว ซ้ำซ้อนถ้าทำที่ Oracle |
| ไม่ทำ background knowledge extraction | Agent + `oracle_learn` + prompt เพียงพอ |
| ChromaDB fail ใน learn = warning ไม่ใช่ error | FTS5 ยังใช้ได้ ไม่ควร block learn ทั้ง request |
