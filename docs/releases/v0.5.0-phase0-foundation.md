# v0.5.0 — Phase 0: Security Foundation + Thai NLP + Embedding Strategy

> **Type:** Major (foundation for all future intelligence upgrades)  
> **Scope:** Security hardening + PyThaiNLP sidecar + embedding versioning + search prep  
> **Risk:** Medium — adds new service (thai-nlp sidecar), changes indexing pipeline  
> **Est. Effort:** ~1 สัปดาห์ (5-7 วัน)  
> **Prerequisites:** v0.4.0 (Oracle Search Quality) applied

---

## Background

Phase 0 เป็นรากฐานที่ต้องวางก่อน feature ทั้งหมดจาก [BEYOND_OPENCLAW.md](./BEYOND_OPENCLAW.md):

1. **Security** — Agent container มองเห็น file ที่ไม่ควรเห็น, secrets อยู่บน disk, IPC ไม่ signed, ChromaDB เปิดโล่ง
2. **Thai NLP** — JellyCore ใช้ภาษาไทย ~90% แต่ไม่มี Thai text processing เลย — FTS5 ไม่ segment, embedding ไม่เข้าใจ, spell check ไม่มี
3. **Embedding** — `all-MiniLM-L6-v2` ไม่เหมาะภาษาไทย แต่เปลี่ยนทันทีเสี่ยง — ต้องวาง versioning system ก่อน

> **หลักคิด:** ทำ security + infrastructure ก่อน เพื่อให้ Phase 1-6 build บน foundation ที่แข็งแรง

---

## Changes

### Part A — Security Foundation (ตาม Master Plan Phase 0 เดิม)

**สถานะ: ✅ ส่วนใหญ่ implement แล้วก่อน v0.5.0**

**รายละเอียดเต็ม:** ดู [MASTER_PLAN/Phase_0_Security_Foundation/](./MASTER_PLAN/Phase_0_Security_Foundation/_OVERVIEW.md)

| # | Item | สถานะ | หมายเหตุ |
|---|------|-------|---------|
| A.1 | Oracle V2 → Docker service แยก | ✅ Done | `docker-compose.yml` มี oracle service แล้ว |
| A.2 | MCP-HTTP Bridge | ✅ Done | `oracle-handler.ts` เรียก HTTP API อยู่แล้ว |
| A.3 | ตัด Project Root Mount | ✅ Done | `buildVolumeMounts()` mount เฉพาะ group folder |
| A.4 | Encrypt WhatsApp Auth | ⬜ Deferred | `encrypted-auth.ts` มี แต่ยังไม่ active |
| A.5 | IPC Integrity Signing | ✅ Done | `ipc-signing.ts` + HMAC |
| A.6 | Secrets via Env Vars Only | ✅ Done | `.env` + docker-compose environment |
| A.7 | Knowledge Base Split | ✅ Done | `oracle-knowledge-private` volume |
| A.8 | ChromaDB Authentication | ✅ Done | `CHROMA_SERVER_AUTHN_PROVIDER` configured |

---

### Part B — Thai NLP Sidecar (ใหม่ จาก PYTHAINLP_INTEGRATION.md)

**รายละเอียดเต็ม:** ดู [PYTHAINLP_INTEGRATION.md](./PYTHAINLP_INTEGRATION.md)

#### B.1 — สร้าง `thai-nlp-sidecar/` service

**ไฟล์ใหม่:**
```
thai-nlp-sidecar/
├── Dockerfile
├── requirements.txt     # fastapi, uvicorn, pythainlp
├── main.py              # FastAPI endpoints
└── README.md
```

**Endpoints:**
- `POST /tokenize` — word segmentation (newmm engine)
- `POST /normalize` — Thai text normalization
- `POST /spellcheck` — spell correction
- `POST /chunk` — sentence-aware document chunking
- `POST /stopwords` — stop word filtering
- `GET /health` — health check + version

**Docker Compose:**
```yaml
thai-nlp:
  build: ./thai-nlp-sidecar
  restart: unless-stopped
  ports:
    - "47780:8000"
  environment:
    - PYTHAINLP_DATA_DIR=/data/pythainlp
  volumes:
    - ./data/pythainlp:/data/pythainlp
  deploy:
    resources:
      limits:
        memory: 256M
```

**LOC est.:** ~120 (Python) + ~30 (Dockerfile + config)

#### B.2 — สร้าง ThaiNlpClient ใน Oracle V2

**ไฟล์ใหม่:** `oracle-v2/src/thai-nlp-client.ts`

```typescript
export class ThaiNlpClient {
  constructor(private baseUrl: string, private timeout: number = 2000) {}

  async tokenize(text: string): Promise<{ tokens: string[]; segmented: string }>;
  async normalize(text: string): Promise<{ normalized: string }>;
  async spellcheck(text: string): Promise<{ corrected: string }>;
  async chunk(text: string, maxTokens?: number, overlap?: number): Promise<{ chunks: string[] }>;
}
```

- Timeout 2s per request
- **Graceful degradation:** ทุก method มี `catch` → fallback to passthrough (ทำงานเหมือนเดิม)
- Singleton: ใช้ร่วมกัน เหมือน `getChromaClient()`

**LOC est.:** ~80

#### B.3 — แก้ Search Query Preprocessing

**File:** `oracle-v2/src/server/handlers.ts` → `handleSearch()`

**Before:**
```typescript
const safeQuery = query.replace(/[?*+\-()^~"':]/g, ' ').replace(/\s+/g, ' ').trim();
```

**After:**
```typescript
// Thai NLP preprocessing (graceful — falls back if sidecar down)
const thaiNlp = getThaiNlpClient();
const { normalized } = await thaiNlp.normalize(query);
const { corrected } = await thaiNlp.spellcheck(normalized);
const { segmented } = await thaiNlp.tokenize(corrected);
const safeQuery = segmented.replace(/[?*+\-()^~"':]/g, ' ').replace(/\s+/g, ' ').trim();
```

**ผลลัพธ์:**  
`"อยากกินขาวผัดกุง"` → normalize → spellcheck `"อยากกินข้าวผัดกุ้ง"` → tokenize `"อยาก กิน ข้าวผัด กุ้ง"` → FTS5 MATCH ได้จริง

**LOC est.:** ~15

#### B.4 — แก้ Indexing Pipeline

**File:** `oracle-v2/src/server/handlers.ts` → `handleLearn()` + indexer

**ปัจจุบัน:** Insert raw text → FTS5  
**เปลี่ยนเป็น:** Normalize → Tokenize → Insert segmented text → FTS5

```typescript
// Before FTS5 insert
const { normalized } = await thaiNlp.normalize(content);
const { segmented } = await thaiNlp.tokenize(normalized);

// FTS5 stores segmented text for accurate MATCH
sqlite.prepare('INSERT INTO oracle_fts (id, content) VALUES (?, ?)').run(id, segmented);
```

**Critical rule:** Query time + index time ต้องใช้ tokenizer engine เดียวกัน (`newmm`)

**LOC est.:** ~20

#### B.5 — Re-indexing Script

**ไฟล์ใหม่:** `oracle-v2/scripts/reindex-with-thai-nlp.ts`

```bash
# Usage
bun run scripts/reindex-with-thai-nlp.ts

# What it does:
# 1. Read all oracle_documents
# 2. For each: normalize → tokenize via sidecar
# 3. UPDATE oracle_fts SET content = segmented_text
# 4. Report stats
```

**Safety:**
- Backup FTS5 table ก่อน
- แสดง progress bar
- ทำ batch 50 docs/batch (ไม่ overwhelm sidecar)
- Skip ถ้า sidecar down (abort with clear message)

**LOC est.:** ~60

**Part B Subtotal:** ~325 LOC across 5 items

---

### Part C — Embedding Versioning System (ใหม่)

เตรียมโครงสร้างสำหรับเปลี่ยน embedding model ใน Phase 1 โดยไม่ต้อง re-index ทั้งหมดทีเดียว

#### C.1 — เพิ่ม embedding metadata ใน schema

**File:** `oracle-v2/src/db/schema.ts`

```sql
ALTER TABLE oracle_documents ADD COLUMN embedding_model TEXT DEFAULT 'all-MiniLM-L6-v2';
ALTER TABLE oracle_documents ADD COLUMN embedding_version INTEGER DEFAULT 1;
ALTER TABLE oracle_documents ADD COLUMN embedding_hash TEXT; -- SHA-256 of content ที่ embed
```

**เหตุผล:**
- เมื่อเปลี่ยน model → รู้ว่า doc ไหนยัง embed ด้วย model เก่า
- เมื่อ content ไม่เปลี่ยน → ไม่ต้อง re-embed (ประหยัด cost)
- Background re-embedding สามารถทำทีละ batch ได้

**LOC est.:** ~20 (migration)

#### C.2 — Embedding Cache Layer

**ไฟล์ใหม่:** `oracle-v2/src/embedding-cache.ts`

```typescript
export class EmbeddingCache {
  // Check if content already embedded with current model
  hasEmbedding(contentHash: string, model: string): boolean;

  // Store embedding metadata
  recordEmbedding(docId: string, model: string, version: number, contentHash: string): void;

  // Get docs that need re-embedding (model changed or content changed)
  getStaleDocuments(currentModel: string): string[];
}
```

**LOC est.:** ~50

**Part C Subtotal:** ~70 LOC across 2 items

---

## File Changelist Summary

| File | Change | LOC est. | Part |
|------|--------|----------|------|
| `docker-compose.yml` | เพิ่ม oracle, chromadb auth, thai-nlp services | ~40 | A+B |
| `nanoclaw/src/container-runner.ts` | Restrict mounts | ~20 | A |
| `nanoclaw/src/whatsapp-auth.ts` | AES-256-GCM encryption | ~40 | A |
| `nanoclaw/src/oracle-handler.ts` | MCP-HTTP bridge | ~50 | A |
| **`thai-nlp-sidecar/`** (ใหม่) | FastAPI + PyThaiNLP + Dockerfile | ~150 | B |
| **`oracle-v2/src/thai-nlp-client.ts`** (ใหม่) | HTTP client with graceful degradation | ~80 | B |
| `oracle-v2/src/server/handlers.ts` | Search preprocessing + indexing | ~35 | B |
| **`oracle-v2/scripts/reindex-with-thai-nlp.ts`** (ใหม่) | Re-index FTS5 with segmentation | ~60 | B |
| `oracle-v2/src/db/schema.ts` | Embedding metadata columns | ~20 | C |
| **`oracle-v2/src/embedding-cache.ts`** (ใหม่) | Embedding version tracking | ~50 | C |
| `oracle-v2/package.json` | Bump `0.4.0` → `0.5.0` | 1 | - |

**Total:** ~575 LOC (new + changed)  
**New files:** 4 + thai-nlp-sidecar directory  
**Services to rebuild:** Oracle V2 + new thai-nlp sidecar  
**NanoClaw rebuild:** Yes (มีแก้ container-runner, oracle-handler, whatsapp-auth)

---

## Dependency Graph

```
         ┌──── A.1 Oracle Docker ────► A.2 MCP Bridge
         │                            ──► A.8 ChromaDB Auth
         │
Phase 0  ├──── A.3-A.7 (parallel, independent)
         │
         ├──── B.1 Thai NLP Sidecar ──► B.2 ThaiNlpClient
         │                            ──► B.3 Search Preprocessing
         │                            ──► B.4 Indexing Pipeline
         │                            ──► B.5 Re-indexing Script
         │
         └──── C.1 Schema Migration ──► C.2 Embedding Cache
```

**Recommended order:**
1. **Day 1:** A.1 + A.8 (Oracle Docker + ChromaDB auth) — infrastructure first
2. **Day 2:** A.3-A.7 (all security items in parallel)
3. **Day 3:** A.2 (MCP bridge — depends on A.1) + B.1 (start sidecar)
4. **Day 4:** B.2 + B.3 + B.4 (Thai NLP integration in Oracle V2)
5. **Day 5:** B.5 (re-index) + C.1 + C.2 (embedding versioning)
6. **Day 6-7:** Testing + verification

---

## Verification

### Part A — Security

```bash
# A.1: Oracle V2 runs as separate Docker service
docker compose ps | grep oracle
curl http://localhost:47778/api/health
# → {"status": "ok", ...}

# A.3: Container cannot see sensitive files
docker exec agent-container ls /workspace/store/auth/
# → ls: cannot access: No such file or directory

# A.5: Unsigned IPC rejected
echo "fake output" > /tmp/test.ipc
# → agent should reject (no HMAC signature)

# A.8: ChromaDB rejects unauthenticated requests
curl http://localhost:8000/api/v1/collections
# → 401 Unauthorized
```

### Part B — Thai NLP

```bash
# B.1: Sidecar health
curl http://localhost:47780/health
# → {"status": "ok", "pythainlp_version": "5.2.0"}

# B.1: Tokenization works
curl -X POST http://localhost:47780/tokenize \
  -H 'Content-Type: application/json' \
  -d '{"text": "อยากกินข้าวผัดกุ้ง"}'
# → {"tokens": ["อยาก", "กิน", "ข้าวผัด", "กุ้ง"], "segmented": "อยาก กิน ข้าวผัด กุ้ง"}

# B.3: Search with Thai text works better
curl "http://localhost:47778/api/search?q=ข้าวผัด&mode=fts"
# → should match documents containing "ข้าวผัดกุ้ง" (was impossible before)

# B.4: Spell correction in search
curl "http://localhost:47778/api/search?q=เหตการณ&mode=hybrid"
# → corrects to "เหตุการณ์" and returns results

# B.5: Re-index completed
bun run scripts/reindex-with-thai-nlp.ts
# → "Re-indexed 5500 documents with Thai segmentation"
```

### Part C — Embedding Versioning

```sql
-- Verify new columns exist
SELECT embedding_model, embedding_version, embedding_hash
FROM oracle_documents LIMIT 1;
-- → 'all-MiniLM-L6-v2', 1, 'abc123...'
```

---

## Graceful Degradation Matrix

| Component Down | ผลกระทบ | Behavior |
|---------------|---------|----------|
| Thai NLP sidecar | Search = เหมือนเดิม (no Thai processing) | ThaiNlpClient fallback → passthrough |
| ChromaDB | Vector search ไม่ทำงาน | FTS5-only mode (มีอยู่แล้ว) |
| Oracle V2 | Knowledge unavailable | NanoClaw uses inline/container without context |

> **หลักการ:** ทุก component ใหม่ต้อง fail gracefully — ไม่เคย crash ระบบทั้งหมด

---

## Decisions

| Decision | Rationale |
|----------|-----------|
| PyThaiNLP เป็น sidecar (ไม่ embed ใน Oracle) | Python vs TypeScript — ต้องแยก process |
| ใช้ newmm engine (ไม่ใช่ attacut/deepcut) | dictionary-based, thread-safe, ไม่ต้อง GPU, best balance |
| ทำ re-index ทั้งหมด (ไม่ทำแค่ docs ใหม่) | Index ต้อง consistent — ถ้า partial จะ search ไม่ match |
| Embedding versioning ก่อนเปลี่ยน model | Migration strategy ก่อน — Phase 1 ค่อยเปลี่ยน model จริง |
| Sidecar timeout 2s | PyThaiNLP tokenize < 50ms ปกติ — 2s เป็น safety net |
| Security + NLP ใน Phase เดียวกัน | ทั้งสองเป็น foundation ที่ไม่ขึ้นกัน — ทำ parallel ได้ |

---

## Rollback Plan

| Situation | Action |
|-----------|--------|
| Thai NLP sidecar ใช้ RAM เกินไป | ลด worker count หรือ disable ชั่วคราว (Oracle works without) |
| Re-index ทำ FTS5 เสีย | Restore from pre-reindex backup (script สร้าง backup อัตโนมัติ) |
| Embedding columns break Drizzle | Migration แยก file — revert migration |
| Security changes lock out agent | Keep backup of old docker-compose.yml + mount config |

---

## Success Criteria

- [ ] **Security:** Agent container ไม่เห็น `store/auth/`, `.env`, `src/`, `ψ/memory/private/`
- [ ] **Security:** ChromaDB ปฏิเสธ unauthenticated connections
- [ ] **Security:** IPC ที่ไม่มี HMAC signature ถูก reject
- [ ] **Thai NLP:** Search query `"ข้าวผัด"` match document ที่มี `"ข้าวผัดกุ้ง"` (ก่อนหน้าไม่ match)
- [ ] **Thai NLP:** Misspelled query `"เหตการณ"` ถูก correct เป็น `"เหตุการณ์"` อัตโนมัติ
- [ ] **Thai NLP:** Sidecar down → Oracle search ทำงานได้ปกติ (graceful degradation)
- [ ] **Embedding:** Schema มี `embedding_model`, `embedding_version`, `embedding_hash`
- [ ] **Embedding:** `EmbeddingCache.getStaleDocuments()` returns correct list เมื่อเปลี่ยน model config

---

## What's Next: Phase 1 Preview

Phase 0 วาง foundation → Phase 1 **ใช้ foundation** เพื่อ upgrade intelligence:

```
Phase 1 (Week 2-3): Performance + Intelligence
├── 1.10 Adaptive Hybrid Search (configurable FTS/vector weights)
├── 1.11 Embedding Model Upgrade (all-MiniLM → multilingual-e5-large)
│   └── ใช้ embedding versioning จาก Phase 0 Part C
│   └── Background re-embed ด้วย new model
├── 1.12 Overlap Chunking (ด้วย sent_tokenize จาก Phase 0 Part B)
│   └── ใช้ /chunk endpoint ของ thai-nlp sidecar
└── Container Warm Pool optimization
```

---

*ไฟล์นี้เป็นส่วนหนึ่งของ [BEYOND_OPENCLAW.md](./BEYOND_OPENCLAW.md) implementation roadmap*  
*ดู PyThaiNLP analysis เพิ่มเติมที่ [PYTHAINLP_INTEGRATION.md](./PYTHAINLP_INTEGRATION.md)*
